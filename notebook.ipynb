{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Public Archive of Police Violence in Cleveland](http://archivingpoliceviolence.org/themes/papvc/images/papvc.png)\n",
    "\n",
    "This is an example of using topic modeling to look at the [Public Archive of Police Violence in Cleveland](http://archivingpoliceviolence.org/) transcripts.\n",
    "\n",
    "First let's convert the transcripts from docx files to text files so we can easily read them in. This assumes that [pandoc](https://github.com/jgm/pandoc/releases/tag/1.19.2.1) is installed and that the transcripts are located in a directory called transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "for pdf_file in glob.glob(\"transcripts/*.docx\"):\n",
    "    txt_file = pdf_file.replace(\".docx\", \".txt\")\n",
    "    if not os.path.isfile(txt_file):\n",
    "        print(\"converting \" + pdf_file)\n",
    "        subprocess.call([\"pandoc\", pdf_file, \"-o\", txt_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a list of stopwords that we know we're not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are %s stopwords 319\n"
     ]
    }
   ],
   "source": [
    "from stopwords import stopwords\n",
    "\n",
    "print(\"There are %s stopwords\", len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like you can add stopwords, just make sure they are lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords.add(\"know\")\n",
    "stopwords.add(\"like\")\n",
    "stopwords.add(\"said\")\n",
    "stopwords.add(\"police\")\n",
    "stopwords.add(\"people\")\n",
    "stopwords.add(\"just\")\n",
    "stopwords.add(\"think\")\n",
    "stopwords.add(\"like\")\n",
    "stopwords.add(\"gonna\")\n",
    "stopwords.add(\"want\")\n",
    "stopwords.add(\"didn\")\n",
    "stopwords.add(\"going\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a function that returns each text transcript as a list of words. It will remove words less than 3 letters in length, and also remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def docs():\n",
    "    for txt_file in glob.glob(\"transcripts/*.txt\"):\n",
    "        text = open(txt_file).read()\n",
    "        words = []\n",
    "        for word in re.split(r'\\W+', text):\n",
    "            if  len(word) > 3 and word.lower() not in stopwords and not re.match('^[A-Z]', word):\n",
    "                words.append(word)\n",
    "        yield words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it works by getting the first document and printing it out. Remember the stopwords have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fiancé', 'goes', 'trouble', 'young', 'child', 'mother', 'daughter', 'sending', 'child', 'play', 'recreation', 'center', 'believe', 'fact', 'security', 'guard', 'understand', 'happened', 'place', 'secured', 'personal', 'experiences', 'couple', 'fiancé', 'come', 'come', 'talk', 'rights', 'sent', 'jail', 'panties', 'house', 'phone', 'hear', 'situation', 'couldn', 'trust', 'clothes', 'coming', 'person', 'habit', 'crime', 'wouldn', 'clothes', 'arrested', 'scared', 'younger', 'nephews', 'future', 'chose', 'children', 'glad', 'worried', 'losing', 'life', 'somebody', 'supposed', 'serve', 'protect']\n"
     ]
    }
   ],
   "source": [
    "print(next(docs()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we're ready to start using gensim to do topic modeling. Let's start by creating our word dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(docs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create our corpus from the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "def ids():\n",
    "    for doc in docs():\n",
    "        yield dictionary.doc2bow(doc)\n",
    "\n",
    "path = \"corpus.mm\"\n",
    "corpora.MmCorpus.serialize(path, ids())\n",
    "corpus = corpora.MmCorpus(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel(\n",
    "    corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=15,\n",
    "    passes=20,\n",
    "    iterations=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = lda.top_topics(corpus, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. weapon, guns, city, person, violence, shooting, thing, shoot, right, father\n",
      "2. belong, officer, line, mean, wrong, guess, kind, better, homeless, issues\n",
      "3. black, right, time, white, things, thing, happened, mean, saying, years\n",
      "4. things, time, black, thing, right, good, come, house, getting, years\n",
      "5. news, indistinct, http, items, archivingpoliceviolence, really, everybody, mean, doing, stuff\n",
      "6. mean, good, policeman, home, time, officer, happened, cause, things, course\n",
      "7. came, mean, time, right, left, happened, come, things, thing, stuff\n",
      "8. little, house, come, bitch, shit, calling, right, make, good, shot\n",
      "9. really, right, trying, stuff, doing, saying, thing, happened, shot, violence\n",
      "10. time, came, happened, stuff, went, mean, actually, come, left, told\n",
      "11. things, overlooked, mean, better, city, feel, reason, inner, protocol, seen\n",
      "12. items, archivingpoliceviolence, http, tell, feel, officers, thing, report, violence, right\n",
      "13. doing, tell, good, thing, stop, protect, life, really, serve, things\n",
      "14. right, mean, black, time, officer, happened, things, seen, belong, kind\n",
      "15. kind, took, standing, need, ground, wasn, homeless, aggravated, threw, little\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for topic in topics:\n",
    "    num += 1\n",
    "    print(\"%s. %s\" % (num, ', '.join([t[1] for t in topic[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
